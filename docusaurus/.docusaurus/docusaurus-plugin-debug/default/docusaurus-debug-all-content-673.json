{
  "docusaurus-plugin-content-docs": {
    "default": {
      "loadedVersions": [
        {
          "versionName": "current",
          "label": "Next",
          "banner": null,
          "badge": false,
          "noIndex": false,
          "className": "docs-version-current",
          "path": "/ai-textbook-physical-ai-humanoid/docs",
          "tagsPath": "/ai-textbook-physical-ai-humanoid/docs/tags",
          "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs",
          "editUrlLocalized": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/i18n/en/docusaurus-plugin-content-docs/current",
          "isLast": true,
          "routePriority": -1,
          "sidebarFilePath": "C:\\Users\\Lenovo\\Desktop\\AI Spec Native Driven Text Book\\docusaurus\\sidebars.js",
          "contentPath": "C:\\Users\\Lenovo\\Desktop\\AI Spec Native Driven Text Book\\docusaurus\\docs",
          "contentPathLocalized": "C:\\Users\\Lenovo\\Desktop\\AI Spec Native Driven Text Book\\docusaurus\\i18n\\en\\docusaurus-plugin-content-docs\\current",
          "docs": [
            {
              "id": "assets/citations",
              "title": "Citations for AI Native Textbook on Physical AI & Humanoid Robotics",
              "description": "References",
              "source": "@site/docs/assets/citations.md",
              "sourceDirName": "assets",
              "slug": "/assets/citations",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/assets/citations",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/assets/citations.md",
              "tags": [],
              "version": "current",
              "frontMatter": {}
            },
            {
              "id": "intro",
              "title": "Welcome to the AI Native Textbook on Physical AI & Humanoid Robotics",
              "description": "This textbook provides a comprehensive guide to understanding and working with Physical AI and Humanoid Robotics through hands-on experiences in simulated and real-world environments.",
              "source": "@site/docs/intro.md",
              "sourceDirName": ".",
              "slug": "/intro",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/intro",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/intro.md",
              "tags": [],
              "version": "current",
              "frontMatter": {},
              "sidebar": "tutorialSidebar",
              "next": {
                "title": "Welcome to the AI Native Textbook on Physical AI & Humanoid Robotics",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/intro"
              }
            },
            {
              "id": "module-1-ros2/integrating-python-agents",
              "title": "Integrating Python Agents with ROS Controllers",
              "description": "One of the key strengths of ROS 2 is its support for multiple programming languages. Python, being the language of choice for many AI and machine learning frameworks, becomes an ideal bridge between AI agents and robot control systems. The rclpy client library allows us to interface Python AI agents with ROS controllers.",
              "source": "@site/docs/module-1-ros2/integrating-python-agents.md",
              "sourceDirName": "module-1-ros2",
              "slug": "/module-1-ros2/integrating-python-agents",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/integrating-python-agents",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-1-ros2/integrating-python-agents.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {
                "sidebar_position": 3,
                "title": "Integrating Python Agents with ROS Controllers"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "ROS 2 Nodes, Topics, and Services",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/nodes-topics-services"
              },
              "next": {
                "title": "URDF for Humanoid Robots",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/urdf-humanoids"
              }
            },
            {
              "id": "module-1-ros2/intro",
              "title": "Introduction to ROS 2",
              "description": "Welcome to the first module of our AI Native Textbook on Physical AI & Humanoid Robotics. This module focuses on the Robotic Nervous System, specifically the Robot Operating System 2 (ROS 2).",
              "source": "@site/docs/module-1-ros2/intro.md",
              "sourceDirName": "module-1-ros2",
              "slug": "/module-1-ros2/intro",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/intro",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-1-ros2/intro.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1,
                "title": "Introduction to ROS 2"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Welcome to the AI Native Textbook on Physical AI & Humanoid Robotics",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/intro"
              },
              "next": {
                "title": "ROS 2 Nodes, Topics, and Services",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/nodes-topics-services"
              }
            },
            {
              "id": "module-1-ros2/nodes-topics-services",
              "title": "ROS 2 Nodes, Topics, and Services",
              "description": "In ROS 2, nodes communicate through a publish-subscribe model using topics, services, and actions. Understanding these communication patterns is essential for building distributed robotic systems.",
              "source": "@site/docs/module-1-ros2/nodes-topics-services.md",
              "sourceDirName": "module-1-ros2",
              "slug": "/module-1-ros2/nodes-topics-services",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/nodes-topics-services",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-1-ros2/nodes-topics-services.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {
                "sidebar_position": 2,
                "title": "ROS 2 Nodes, Topics, and Services"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Introduction to ROS 2",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/intro"
              },
              "next": {
                "title": "Integrating Python Agents with ROS Controllers",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/integrating-python-agents"
              }
            },
            {
              "id": "module-1-ros2/summary-exercises",
              "title": "Summary and Exercises",
              "description": "Summary",
              "source": "@site/docs/module-1-ros2/summary-exercises.md",
              "sourceDirName": "module-1-ros2",
              "slug": "/module-1-ros2/summary-exercises",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/summary-exercises",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-1-ros2/summary-exercises.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {
                "sidebar_position": 5,
                "title": "Summary and Exercises"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "URDF for Humanoid Robots",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/urdf-humanoids"
              },
              "next": {
                "title": "Introduction to Digital Twins in Robotics",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/intro"
              }
            },
            {
              "id": "module-1-ros2/urdf-humanoids",
              "title": "URDF for Humanoid Robots",
              "description": "URDF (Unified Robot Description Format) is an XML format for representing a robot model. URDF is used extensively in ROS to describe robots in terms of their joints, links, visual and collision properties, and more. When designing humanoid robots, URDF plays a crucial role in specifying the physical structure and kinematic properties.",
              "source": "@site/docs/module-1-ros2/urdf-humanoids.md",
              "sourceDirName": "module-1-ros2",
              "slug": "/module-1-ros2/urdf-humanoids",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/urdf-humanoids",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-1-ros2/urdf-humanoids.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {
                "sidebar_position": 4,
                "title": "URDF for Humanoid Robots"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Integrating Python Agents with ROS Controllers",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/integrating-python-agents"
              },
              "next": {
                "title": "Summary and Exercises",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/summary-exercises"
              }
            },
            {
              "id": "module-2-digital-twin/gazebo-physics",
              "title": "Physics Simulation in Gazebo",
              "description": "Gazebo is a robotics simulator that provides realistic physics simulation, high-quality graphics, and convenient programmatic interfaces. It is widely used in robotics research and development to simulate robots in complex environments.",
              "source": "@site/docs/module-2-digital-twin/gazebo-physics.md",
              "sourceDirName": "module-2-digital-twin",
              "slug": "/module-2-digital-twin/gazebo-physics",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/gazebo-physics",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-2-digital-twin/gazebo-physics.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {
                "sidebar_position": 2,
                "title": "Physics Simulation in Gazebo"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Introduction to Digital Twins in Robotics",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/intro"
              },
              "next": {
                "title": "Unity Integration for Human-Robot Interaction",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/unity-integration"
              }
            },
            {
              "id": "module-2-digital-twin/intro",
              "title": "Introduction to Digital Twins in Robotics",
              "description": "The digital twin concept involves creating a virtual replica of a physical system. In robotics, this means having a virtual representation of a robot that mirrors its physical counterpart. This module focuses on using Gazebo and Unity for creating realistic physics simulations and environments for robots.",
              "source": "@site/docs/module-2-digital-twin/intro.md",
              "sourceDirName": "module-2-digital-twin",
              "slug": "/module-2-digital-twin/intro",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/intro",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-2-digital-twin/intro.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1,
                "title": "Introduction to Digital Twins in Robotics"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Summary and Exercises",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-1-ros2/summary-exercises"
              },
              "next": {
                "title": "Physics Simulation in Gazebo",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/gazebo-physics"
              }
            },
            {
              "id": "module-2-digital-twin/unity-integration",
              "title": "Unity Integration for Human-Robot Interaction",
              "description": "Unity is a powerful cross-platform game engine that has found applications in robotics simulation and human-robot interaction prototyping. Its real-time rendering capabilities and extensive asset ecosystem make it suitable for creating high-fidelity visualizations and user interfaces for robot systems.",
              "source": "@site/docs/module-2-digital-twin/unity-integration.md",
              "sourceDirName": "module-2-digital-twin",
              "slug": "/module-2-digital-twin/unity-integration",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/unity-integration",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-2-digital-twin/unity-integration.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {
                "sidebar_position": 3,
                "title": "Unity Integration for Human-Robot Interaction"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Physics Simulation in Gazebo",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/gazebo-physics"
              },
              "next": {
                "title": "Introduction to AI-Robot Brain with NVIDIA Isaac",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/intro"
              }
            },
            {
              "id": "module-3-ai-brain/intro",
              "title": "Introduction to AI-Robot Brain with NVIDIA Isaac",
              "description": "This module explores the AI-Robot brain, focusing on advanced perception, training, and integration with NVIDIA Isaac platforms. We'll learn about NVIDIA Isaac Sim for photorealistic simulation and synthetic data generation, Isaac ROS for hardware-accelerated navigation, and Nav2 for path planning.",
              "source": "@site/docs/module-3-ai-brain/intro.md",
              "sourceDirName": "module-3-ai-brain",
              "slug": "/module-3-ai-brain/intro",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/intro",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-3-ai-brain/intro.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1,
                "title": "Introduction to AI-Robot Brain with NVIDIA Isaac"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Unity Integration for Human-Robot Interaction",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-2-digital-twin/unity-integration"
              },
              "next": {
                "title": "NVIDIA Isaac Sim for Photorealistic Simulation",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/isaac-sim"
              }
            },
            {
              "id": "module-3-ai-brain/isaac-sim",
              "title": "NVIDIA Isaac Sim for Photorealistic Simulation",
              "description": "NVIDIA Isaac Sim is a robotics simulator based on NVIDIA Omniverse that provides advanced physics simulation capabilities and photorealistic rendering for robotics applications. It enables rapid development and testing of robot applications in virtual environments that closely match real-world conditions.",
              "source": "@site/docs/module-3-ai-brain/isaac-sim.md",
              "sourceDirName": "module-3-ai-brain",
              "slug": "/module-3-ai-brain/isaac-sim",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/isaac-sim",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-3-ai-brain/isaac-sim.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {
                "sidebar_position": 2,
                "title": "NVIDIA Isaac Sim for Photorealistic Simulation"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Introduction to AI-Robot Brain with NVIDIA Isaac",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/intro"
              },
              "next": {
                "title": "Isaac ROS for Hardware-Accelerated VSLAM",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/visual-slam"
              }
            },
            {
              "id": "module-3-ai-brain/nav2-humanoid",
              "title": "Nav2 for Path Planning in Humanoid Movement",
              "description": "Navigation 2 (Nav2) is the next-generation navigation system for ROS 2, designed to provide path planning and navigation capabilities for mobile robots. This section focuses on adapting Nav2 for the specific challenges of bipedal humanoid movement, which requires specialized approaches to path planning and locomotion compared to wheeled robots.",
              "source": "@site/docs/module-3-ai-brain/nav2-humanoid.md",
              "sourceDirName": "module-3-ai-brain",
              "slug": "/module-3-ai-brain/nav2-humanoid",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/nav2-humanoid",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-3-ai-brain/nav2-humanoid.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 4,
              "frontMatter": {
                "sidebar_position": 4,
                "title": "Nav2 for Path Planning in Humanoid Movement"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Isaac ROS for Hardware-Accelerated VSLAM",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/visual-slam"
              },
              "next": {
                "title": "Introduction to Vision-Language-Action (VLA)",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/intro"
              }
            },
            {
              "id": "module-3-ai-brain/visual-slam",
              "title": "Isaac ROS for Hardware-Accelerated VSLAM",
              "description": "Visual Simultaneous Localization and Mapping (VSLAM) is a critical capability for autonomous robots operating in unknown environments. NVIDIA Isaac ROS provides hardware-accelerated VSLAM implementations that leverage GPU acceleration for improved performance and accuracy. This section covers implementing VSLAM systems with Isaac ROS and integrating them into navigation workflows.",
              "source": "@site/docs/module-3-ai-brain/visual-slam.md",
              "sourceDirName": "module-3-ai-brain",
              "slug": "/module-3-ai-brain/visual-slam",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/visual-slam",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-3-ai-brain/visual-slam.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {
                "sidebar_position": 3,
                "title": "Isaac ROS for Hardware-Accelerated VSLAM"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "NVIDIA Isaac Sim for Photorealistic Simulation",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/isaac-sim"
              },
              "next": {
                "title": "Nav2 for Path Planning in Humanoid Movement",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/nav2-humanoid"
              }
            },
            {
              "id": "module-4-vla/capstone-project",
              "title": "Capstone Project - The Autonomous Humanoid",
              "description": "The capstone project brings together all the concepts learned in previous modules to create an integrated autonomous humanoid robot system. This project involves implementing a simulated humanoid robot that can receive voice commands, plan paths, navigate obstacles, identify objects, and manipulate them based on user instructions.",
              "source": "@site/docs/module-4-vla/capstone-project.md",
              "sourceDirName": "module-4-vla",
              "slug": "/module-4-vla/capstone-project",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/capstone-project",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-4-vla/capstone-project.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 5,
              "frontMatter": {
                "sidebar_position": 5,
                "title": "Capstone Project - The Autonomous Humanoid"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Cognitive Planning with LLMs",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/cognitive-planning"
              }
            },
            {
              "id": "module-4-vla/cognitive-planning",
              "title": "Cognitive Planning with LLMs",
              "description": "Large Language Models (LLMs) have emerged as powerful tools for natural language understanding and generation. In robotics, they can serve as high-level cognitive planners that interpret natural language commands and translate them into sequences of executable robot actions. This section explores how to integrate LLMs into robotic systems for cognitive planning.",
              "source": "@site/docs/module-4-vla/cognitive-planning.md",
              "sourceDirName": "module-4-vla",
              "slug": "/module-4-vla/cognitive-planning",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/cognitive-planning",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-4-vla/cognitive-planning.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 3,
              "frontMatter": {
                "sidebar_position": 3,
                "title": "Cognitive Planning with LLMs"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Voice-to-Action with OpenAI Whisper",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/voice-to-action"
              },
              "next": {
                "title": "Capstone Project - The Autonomous Humanoid",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/capstone-project"
              }
            },
            {
              "id": "module-4-vla/intro",
              "title": "Introduction to Vision-Language-Action (VLA)",
              "description": "This module explores the convergence of Large Language Models (LLMs) and robotics, specifically focusing on how to bridge high-level language commands with low-level robot actions. We'll explore Voice-to-Action systems using OpenAI Whisper and cognitive planning for natural language processing.",
              "source": "@site/docs/module-4-vla/intro.md",
              "sourceDirName": "module-4-vla",
              "slug": "/module-4-vla/intro",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/intro",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-4-vla/intro.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 1,
              "frontMatter": {
                "sidebar_position": 1,
                "title": "Introduction to Vision-Language-Action (VLA)"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Nav2 for Path Planning in Humanoid Movement",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-3-ai-brain/nav2-humanoid"
              },
              "next": {
                "title": "Voice-to-Action with OpenAI Whisper",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/voice-to-action"
              }
            },
            {
              "id": "module-4-vla/voice-to-action",
              "title": "Voice-to-Action with OpenAI Whisper",
              "description": "Natural human-machine interaction relies heavily on the ability for humans to communicate with robots using natural language. This section focuses on implementing voice-to-action systems that allow users to control robots using spoken commands, leveraging OpenAI Whisper for voice recognition and interpretation.",
              "source": "@site/docs/module-4-vla/voice-to-action.md",
              "sourceDirName": "module-4-vla",
              "slug": "/module-4-vla/voice-to-action",
              "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/voice-to-action",
              "draft": false,
              "unlisted": false,
              "editUrl": "https://github.com/AI-Textbook-Project/ai-textbook-physical-ai-humanoid/edit/main/docs/module-4-vla/voice-to-action.md",
              "tags": [],
              "version": "current",
              "sidebarPosition": 2,
              "frontMatter": {
                "sidebar_position": 2,
                "title": "Voice-to-Action with OpenAI Whisper"
              },
              "sidebar": "tutorialSidebar",
              "previous": {
                "title": "Introduction to Vision-Language-Action (VLA)",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/intro"
              },
              "next": {
                "title": "Cognitive Planning with LLMs",
                "permalink": "/ai-textbook-physical-ai-humanoid/docs/module-4-vla/cognitive-planning"
              }
            }
          ],
          "drafts": [],
          "sidebars": {
            "tutorialSidebar": [
              {
                "type": "category",
                "label": "Introduction",
                "items": [
                  {
                    "type": "doc",
                    "id": "intro"
                  }
                ],
                "link": {
                  "type": "doc",
                  "id": "intro"
                },
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 1: The Robotic Nervous System (ROS 2)",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-1-ros2/intro"
                  },
                  {
                    "type": "doc",
                    "id": "module-1-ros2/nodes-topics-services"
                  },
                  {
                    "type": "doc",
                    "id": "module-1-ros2/integrating-python-agents"
                  },
                  {
                    "type": "doc",
                    "id": "module-1-ros2/urdf-humanoids"
                  },
                  {
                    "type": "doc",
                    "id": "module-1-ros2/summary-exercises"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 2: The Digital Twin (Gazebo & Unity)",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-2-digital-twin/intro"
                  },
                  {
                    "type": "doc",
                    "id": "module-2-digital-twin/gazebo-physics"
                  },
                  {
                    "type": "doc",
                    "id": "module-2-digital-twin/unity-integration"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 3: The AI-Robot Brain (NVIDIA Isaac)",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-3-ai-brain/intro"
                  },
                  {
                    "type": "doc",
                    "id": "module-3-ai-brain/isaac-sim"
                  },
                  {
                    "type": "doc",
                    "id": "module-3-ai-brain/visual-slam"
                  },
                  {
                    "type": "doc",
                    "id": "module-3-ai-brain/nav2-humanoid"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              },
              {
                "type": "category",
                "label": "Module 4: Vision-Language-Action (VLA)",
                "items": [
                  {
                    "type": "doc",
                    "id": "module-4-vla/intro"
                  },
                  {
                    "type": "doc",
                    "id": "module-4-vla/voice-to-action"
                  },
                  {
                    "type": "doc",
                    "id": "module-4-vla/cognitive-planning"
                  },
                  {
                    "type": "doc",
                    "id": "module-4-vla/capstone-project"
                  }
                ],
                "collapsed": true,
                "collapsible": true
              }
            ]
          }
        }
      ]
    }
  },
  "docusaurus-plugin-content-blog": {
    "default": {
      "blogSidebarTitle": "Recent posts",
      "blogPosts": [],
      "blogListPaginated": [],
      "blogTags": {},
      "blogTagsListPath": "/ai-textbook-physical-ai-humanoid/blog/tags",
      "blogTagsPaginated": []
    }
  },
  "docusaurus-plugin-content-pages": {
    "default": [
      {
        "type": "jsx",
        "permalink": "/ai-textbook-physical-ai-humanoid/",
        "source": "@site/src/pages/index.jsx"
      },
      {
        "type": "jsx",
        "permalink": "/ai-textbook-physical-ai-humanoid/modules",
        "source": "@site/src/pages/modules.jsx"
      },
      {
        "type": "jsx",
        "permalink": "/ai-textbook-physical-ai-humanoid/module/content",
        "source": "@site/src/pages/module/content.jsx"
      },
      {
        "type": "jsx",
        "permalink": "/ai-textbook-physical-ai-humanoid/module/",
        "source": "@site/src/pages/module/index.jsx"
      }
    ]
  },
  "docusaurus-plugin-debug": {},
  "docusaurus-theme-classic": {},
  "docusaurus-bootstrap-plugin": {},
  "docusaurus-mdx-fallback-plugin": {}
}